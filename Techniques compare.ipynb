{
 "metadata": {
  "name": "",
  "signature": "sha256:522d81b19deeedb926c0cc7224fbdaede29b050c15204a42e34f1023a81b4e7b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from sklearn.svm import SVDD\n",
      "from sklearn.metrics import pairwise_distances\n",
      "import pandas as pd\n",
      "from random import sample\n",
      "import sys\n",
      "import os\n",
      "from sklearn.cross_validation import KFold\n",
      "from scipy.linalg import cholesky\n",
      "from sklearn.cross_validation import train_test_split \n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.utils import check_random_state\n",
      "from scipy.spatial import cKDTree\n",
      "from sklearn.utils import array2d\n",
      "import time\n",
      "nu = 0.1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def SMOTE(X, n_samples, k=5, dist_power=2, multiple=False, sample_weight=None,\n",
      "          random_state=None):\n",
      "    \"\"\"\n",
      "    Returns n_samples of synthetic samples from X generated by SMOTE.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like, shape = [n_minority_samples, n_features]\n",
      "        Holds the minority samples\n",
      "    n_samples : int\n",
      "        Number of new synthetic samples.\n",
      "    k : int\n",
      "        Number of nearest neighbours.\n",
      "    dist_power : float, int\n",
      "        Positive power in ditance metrics.\n",
      "    random_state : None or int\n",
      "        Seed for random generator.\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    smoted_X : array, shape = [n_samples, n_features]\n",
      "        Synthetic samples\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(X) is pd.core.frame.DataFrame:\n",
      "        X = X.values\n",
      "\n",
      "    rng = check_random_state(random_state)\n",
      "    n_minor, n_features = X.shape\n",
      "    k = min([n_minor - 1, k])\n",
      "\n",
      "    # Learn nearest neighbours\n",
      "    nn_tree = cKDTree(X)\n",
      "\n",
      "    if multiple:\n",
      "        smoted_X = X.copy()\n",
      "        if sample_weight is not None:\n",
      "            weight_smoted = sample_weight.copy()\n",
      "        nn_dist, nn_idx = nn_tree.query(smoted_X, k=k + 1, p=dist_power)\n",
      "        nn_idx = nn_idx[:, 1:]\n",
      "        for i in xrange(n_samples):\n",
      "            start_idx = rng.choice(len(smoted_X))\n",
      "            start = smoted_X[start_idx, :]\n",
      "            end_idx = nn_idx[start_idx, rng.choice(k)]\n",
      "            end = smoted_X[end_idx, :]\n",
      "            shift = rng.rand()\n",
      "            new_point = [start * shift + end * (1. - shift)]\n",
      "            new_nn_idx = np.argsort(\n",
      "                distance_matrix(smoted_X, new_point,\n",
      "                                p=dist_power).T)[::-1][0][:k]\n",
      "            smoted_X = np.vstack((smoted_X, new_point))\n",
      "            nn_idx = np.vstack((nn_idx, new_nn_idx))\n",
      "            if sample_weight is not None:\n",
      "                weight_smoted = \\\n",
      "                    np.concatenate((weight_smoted,\n",
      "                                    weight_smoted[start_idx] * shift +\n",
      "                                    (1. - shift) * weight_smoted[end_idx]))\n",
      "\n",
      "    else:\n",
      "        start_indices = rng.choice(len(X), size=(n_samples,))\n",
      "        starts = X[start_indices, :]\n",
      "        nn_dists, nn_idx = nn_tree.query(starts, k=k + 1, p=dist_power)\n",
      "        end_indices = nn_idx[np.arange(n_samples),\n",
      "                             rng.choice(np.arange(1, k + 1), n_samples)]\n",
      "        ends = X[end_indices, :]\n",
      "        shifts = rng.rand(n_samples)\n",
      "        smoted_X = starts * np.repeat(array2d(shifts).T, n_features, axis=1) \\\n",
      "            + ends * np.repeat(array2d(1. - shifts).T, n_features, axis=1)\n",
      "        smoted_X = np.vstack((X, smoted_X))\n",
      "        if sample_weight is not None:\n",
      "            weight_smoted = sample_weight[start_indices] * shifts\\\n",
      "                + (1. - shifts) * sample_weight[end_indices]\n",
      "    if sample_weight is None:\n",
      "        return smoted_X\n",
      "    else:\n",
      "        return smoted_X, np.concatenate((sample_weight, weight_smoted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_synthetic_data(size, dim=2, centroid_count=2, centroid_dispersion=1):\n",
      "    size = int(size)\n",
      "    centroids = np.random.rand(centroid_count, dim) * 10 - 5\n",
      "    all_data_part = []\n",
      "    for point in centroids:\n",
      "        covariation_matrix = np.random.randn(dim, dim)\n",
      "        covariation_matrix = np.dot(covariation_matrix, covariation_matrix.T)\n",
      "        covariation_matrix = cholesky(covariation_matrix)\n",
      "        data_part = np.random.randn(int(size / centroid_count), dim)\n",
      "        data_part = np.dot(data_part, covariation_matrix) + point\n",
      "        all_data_part.append(data_part)\n",
      "    data = np.concatenate(all_data_part, axis=0)\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_outlier(size, dim=2, space=1000):\n",
      "    size = int(size)\n",
      "    outliers = (np.random.rand(size, dim) - 0.5) * space * 2\n",
      "    return outliers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_dataset(size, outliers_part=0.12, dim=2, centroid_count=2, centroid_dispersion=1):\n",
      "    inliers = generate_synthetic_data(size * (1 - outliers_part), \n",
      "                                               dim, centroid_count, \n",
      "                                               centroid_dispersion)\n",
      "    outliers = generate_outlier(size*outliers_part, dim, space=centroid_dispersion*50)\n",
      "    data = np.concatenate([inliers, outliers], axis=0)\n",
      "    data = pd.DataFrame(data)\n",
      "    data['label'] = ['target'] * len(inliers) + ['outlier'] * len(outliers)\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def validate_classifier_by_random_points_smote(clf, train_x, size=10000):\n",
      "    clf.fit(train_x)\n",
      "    positive_points = SMOTE(train_x, k=5,n_samples=size)\n",
      "    negative_points = np.random.rand(size, train_x.shape[1])\n",
      "    negative_points *= var(train_x)\n",
      "    error = mean(clf.predict(positive_points) == -1)\n",
      "    error += mean(clf.predict(negative_points) == 1)\n",
      "    return error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def validate_classifier(clf, train_x):\n",
      "    train_x, test_x = train_test_split(train_x, test_size=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def model_selection(data, all_gammas, selection_technic):\n",
      "    metrics = zeros(all_gammas.shape[0])\n",
      "    for index, gamma in enumerate(all_gammas):\n",
      "        clf = SVDD(C = 1.0 / 100, gamma=gamma, kernel='rbf')\n",
      "        metrics[index] = selection_technic(clf, data)\n",
      "    return metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}